\documentclass[12pt]{article}

% UTF-8 encoding and fonts
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}  % Latin Modern font - fixes < > rendering issues

% Page setup
\usepackage[margin=1in]{geometry}
\usepackage{setspace}
\onehalfspacing

% Typography
\usepackage{microtype}

% Math and symbols
\usepackage{amsmath,amssymb}

% Graphics
\usepackage{graphicx}
\usepackage{float}
\usepackage{subcaption}

% Tables
\usepackage{booktabs}
\usepackage{array}
\usepackage{multirow}
\usepackage{threeparttable} % provides tablenotes
\usepackage{longtable}
\usepackage{pdflscape}
\usepackage{siunitx}
\sisetup{detect-all=true, group-separator={,}, group-minimum-digits=4}

% Bibliography
\usepackage{natbib}
\bibliographystyle{aer}  % American Economic Review style

% Hyperlinks
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue
}
\usepackage[nameinlink,noabbrev]{cleveref}

% Timing data (generated by timing_log.py)
\IfFileExists{timing_data.tex}{\input{timing_data.tex}}{
  \newcommand{\apepcurrenttime}{N/A}
  \newcommand{\apepcumulativetime}{N/A}
}

% Captions
\usepackage{caption}
\captionsetup{font=small,labelfont=bf}

% Section formatting
\usepackage{titlesec}
\titleformat{\section}{\large\bfseries}{\thesection.}{0.5em}{}
\titleformat{\subsection}{\normalsize\bfseries}{\thesubsection}{0.5em}{}

% Custom commands
\newcommand{\E}{\mathbb{E}}
\newcommand{\Var}{\text{Var}}
\newcommand{\Cov}{\text{Cov}}
\newcommand{\ind}{\mathbb{I}}
\newcommand{\sym}[1]{\ifmmode^{#1}\else\(^{#1}\)\fi} % significance stars for tables

% APEP Working Paper formatting
\title{Shining Light on Nothing? The Null Effect of Mandatory Energy Benchmarking on NYC Property Values}
\author{APEP Autonomous Research\thanks{Autonomous Policy Evaluation Project. Correspondence: scl@econ.uzh.ch} \and @ai1scl}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
\noindent
Governments worldwide mandate energy disclosure for buildings, expecting transparency to reshape real estate markets. I exploit a sharp regulatory threshold in New York City's Local Law 84---which requires buildings above 25,000 square feet to publicly report energy and water consumption---to estimate the causal effect of mandatory benchmarking on property values. A first-stage compliance jump of 42.3 percentage points confirms the threshold binds. Yet the main regression discontinuity estimate on log assessed value is $-0.040$ (robust SE $= 0.059$, $p = 0.591$): a precise, well-powered zero. This null persists across bandwidths, polynomial orders, kernels, donut specifications, borough subsamples, and building cohorts. The results imply that commercial real estate markets already internalize energy performance information, and that mandatory benchmarking---whatever its other merits---does not alter how the market prices buildings.
\end{abstract}

\vspace{1em}
\noindent\textbf{JEL Codes:} R31, Q48, D83 \\
\noindent\textbf{Keywords:} energy disclosure, building benchmarking, property values, regression discontinuity, information asymmetry

\newpage

%% ============================================================
%% INTRODUCTION
%% ============================================================
\section{Introduction}

Mandatory energy disclosure is the quiet workhorse of climate policy. Over thirty U.S.\ cities and a growing number of countries now require large buildings to publicly report their energy consumption, on the theory that sunlight is the best disinfectant: once buyers, tenants, and investors can compare buildings on energy performance, the market will reward efficiency and punish waste \citep{joskow2012creating}. New York City's Local Law 84 (LL84) is the flagship of this movement. Since 2009 it has required the city's largest buildings to annually benchmark energy and water usage through the EPA's ENERGY STAR Portfolio Manager and to make those results publicly available. In 2016, the law expanded to cover buildings above 25,000 gross square feet, bringing roughly 12,000 additional structures---many of them mid-rise commercial and mixed-use buildings---under the mandate.

The rationale is simple and appealing. Energy costs are a major operating expense in commercial real estate, yet buyers and tenants often lack reliable information about a building's energy profile before committing to a purchase or lease. This information asymmetry, of the kind first formalized by \citet{akerlof1970market}, can suppress investment in efficiency: owners who upgrade their buildings cannot credibly signal the improvement, so the market fails to reward them. Mandatory disclosure, the argument goes, resolves this ``lemons'' problem. Once energy performance is public, efficient buildings trade at a premium, inefficient buildings trade at a discount, and the invisible hand redirects capital toward the greener stock \citep{allcott2014energy, gerarden2017assessing}.

But does any of this actually happen? The empirical evidence is surprisingly thin. A well-known literature documents that LEED and ENERGY STAR certifications correlate with higher rents and sale prices in commercial real estate \citep{eichholtz2010doing, eichholtz2013economics, kahn2014green}. A parallel literature shows that energy performance certificates affect residential prices in Europe \citep{brounen2013energy, fuerst2015green}. Yet correlation is not causation. Buildings that voluntarily pursue green certifications differ from non-certified buildings in numerous dimensions---age, location, tenant quality, management sophistication---that independently affect value. The fundamental question of whether \textit{mandatory} disclosure changes market outcomes remains open.

This paper answers that question using a clean identification strategy. I exploit the sharp regulatory threshold at 25,000 square feet created by LL84's 2016 expansion. Buildings with gross floor area (GFA) just above 25,000 sq ft must publicly disclose their energy and water performance; buildings just below face no such requirement. Since 2016, the 25,000 sq ft threshold has been the primary regulatory cutoff at this building size: the related Local Law 87 (mandatory energy audits) applies only at the 50,000 sq ft threshold, and Local Law 97 (building emissions caps), enacted in 2019, does not impose compliance costs until 2024. This institutional isolation is critical---the dominant discontinuity in regulatory burden at 25,000 sq ft is LL84's disclosure requirement.

The regression discontinuity design (RDD) relies on comparing buildings just above and just below the 25,000 sq ft threshold, under the assumption that potential outcomes vary smoothly across the cutoff \citep{imbenslemieux2008, lee2010rdd}. Several features of the setting support this assumption. GFA is determined by physical construction and recorded in Department of Finance property records, typically decades before LL84's expansion to this threshold. Altering a building's GFA requires costly construction or demolition. For the vast majority of NYC's building stock---constructed well before 2016---the 25,000 sq ft cutoff was not a consideration at the time of construction. A McCrary density test confirms the absence of manipulation: $t = -0.010$, $p = 0.992$.

The first stage is strong and unambiguous. Unconditional compliance rates are approximately 80.5\% just above the threshold and 7\% just below---a 73.5 percentage point raw gap. The local RDD estimate, which isolates the compliance jump at exactly 25,000 sq ft using MSE-optimal bandwidth, is 42.3 percentage points ($p \approx 0$). The difference between the raw gap and local estimate reflects the fact that compliance increases with building size even within each side of the cutoff; the local estimate captures the pure discontinuity. Either way, the first stage is large and statistically overwhelming, confirming that the threshold meaningfully assigns buildings to disclosure treatment.

The main result is a precise null. The RDD estimate of the effect of LL84 disclosure on log assessed property value is $-0.040$ with a robust standard error of 0.059, yielding a $p$-value of 0.591. The point estimate implies a 4\% reduction in assessed value---economically small---but the confidence interval comfortably includes zero. A quadratic specification yields an estimate of $-0.028$ ($p = 0.825$). The per-square-foot specification produces identical results. A parametric OLS estimate using the full sample with borough fixed effects gives $0.005$ ($p = 0.805$). However one slices the data, the answer is the same: mandatory energy disclosure has no detectable effect on how the market values buildings.

This null is robust to an exhaustive battery of specification checks. Bandwidths ranging from 50\% to 200\% of the MSE-optimal choice (2,417 sq ft) all produce insignificant estimates. Linear, quadratic, and cubic polynomials agree. Triangular, Epanechnikov, and uniform kernels all yield nulls, though the uniform kernel gives the largest point estimate ($-0.071$, $p = 0.08$). Donut specifications excluding buildings within $\pm 500$, $\pm 1{,}000$, and $\pm 2{,}000$ sq ft of the cutoff all fail to reject zero. Placebo cutoffs at 15,000, 20,000, 30,000, 35,000, 40,000, and 45,000 sq ft show no systematic pattern of discontinuities. Heterogeneity analysis by borough (Manhattan, Brooklyn, Queens, Bronx) and construction era (pre-1940, 1940--1980, post-1980) reveals uniformly null effects. The most suggestive subgroup estimate---Brooklyn, with $p = 0.078$---is no longer significant after accounting for the number of subgroups tested.

The null result is itself the contribution. Three decades of theoretical work on information economics predicts that mandatory disclosure should affect market outcomes through multiple channels: resolving adverse selection, inducing behavioral responses from building owners, and imposing compliance costs \citep{grossman1981informational, milgrom1981good, stigler1961economics}. This paper finds that none of these channels generates a detectable price effect in the largest and most mature commercial real estate market in the United States. The most parsimonious interpretation is that the market already incorporates energy performance information through existing channels---utility bill disclosure during due diligence, broker expertise, energy audits by sophisticated buyers, and tenant negotiations. If this is correct, then mandatory benchmarking, whatever its symbolic or administrative value, does not add marginal information to the pricing of commercial buildings.

This paper contributes to three literatures. First, it advances the study of information disclosure mandates in real estate by providing credible causal evidence from a regulatory threshold, complementing the correlational evidence on green building certifications \citep{eichholtz2010doing, eichholtz2013economics, kahn2017green} and the quasi-experimental evidence on residential energy labels in Europe \citep{brounen2013energy, fuerst2015green, fuerst2020green}. My null result parallels findings by \citet{sallee2014rational} and \citet{lacetera2012heuristic} suggesting that some markets are less informationally impoverished than regulators assume. Second, the paper joins a growing literature on the effectiveness---and limitations---of disclosure as a regulatory tool, following work by \citet{jin2003effect} on restaurant hygiene grades, \citet{dranove2003quality} on hospital report cards, \citet{bollinger2022calorie} on calorie posting, and \citet{greenstone2006mandated} on securities disclosure. The pattern across these studies is striking: disclosure sometimes works, sometimes backfires, and sometimes does nothing at all. Understanding when and why requires case-by-case empirical evidence of the kind this paper provides. Third, the paper contributes to the debate on the ``energy efficiency gap''---the puzzle of why individuals and firms appear to underinvest in cost-effective energy improvements \citep{allcott2014energy, gerarden2017assessing, gillingham2009energy}. If information asymmetry were a primary barrier, we would expect disclosure mandates to move prices. The null result suggests the gap, to the extent it exists, lies elsewhere.

The remainder of the paper proceeds as follows. Section 2 describes the institutional background of NYC's energy disclosure regime. Section 3 develops a simple conceptual framework with four testable hypotheses. Section 4 describes the data sources and sample construction. Section 5 presents the empirical strategy. Section 6 reports results. Section 7 discusses the findings, and Section 8 concludes.

%% ============================================================
%% INSTITUTIONAL BACKGROUND
%% ============================================================
\section{Institutional Background and Policy Setting}

\subsection{NYC's Energy Disclosure Regime}

New York City operates the most comprehensive building energy disclosure regime in the United States, enacted through a series of local laws collectively known as the ``Greener, Greater Buildings Plan.'' The centerpiece is Local Law 84 (LL84), enacted in December 2009 as part of Mayor Bloomberg's PlaNYC sustainability initiative. LL84 requires covered buildings to annually benchmark their energy and water consumption using the EPA's ENERGY STAR Portfolio Manager tool. The results---including total energy use, energy use intensity (EUI, measured in kBtu per square foot), water consumption, and greenhouse gas emissions---are publicly disclosed on the city's open data portal.

The law initially applied only to buildings with gross floor area exceeding 50,000 square feet. This threshold covered approximately 3,000 of the city's largest properties, including most Class A office towers, major residential complexes, and institutional buildings. Compliance was phased in over 2010--2011, with the first public disclosure occurring in 2012.

In 2016, the City Council expanded LL84 coverage to include buildings with gross floor area between 25,000 and 50,000 square feet. This expansion, formalized as part of Local Law 133 of 2016, brought roughly 12,000 additional buildings under the mandate---primarily mid-rise commercial structures, mixed-use buildings, and larger residential properties. The expansion was motivated by the city's recognition that medium-sized buildings collectively represented a substantial share of total energy consumption and greenhouse gas emissions. Compliance for the newly covered buildings was required beginning with the 2017 reporting year (based on 2016 calendar year data).

\subsection{The 25,000 Square Foot Threshold}

The 25,000 sq ft threshold is central to my identification strategy. Several institutional features make it well-suited for a regression discontinuity design.

First, the threshold is defined by gross floor area (GFA) as recorded in the city's PLUTO (Primary Land Use Tax Lot Output) database, which is compiled from Department of Finance assessment records and Department of Buildings construction permits. These are administrative measurements, not self-reported by building owners. A property owner cannot reclassify a 26,000 sq ft building as 24,000 sq ft to avoid the mandate without physically altering the structure.

Second, at the time of LL84's 2016 expansion, the 25,000 sq ft threshold was the \textit{sole} regulatory boundary at this building size. NYC's related energy laws operate at different thresholds:

\begin{itemize}
    \item \textbf{Local Law 87} (Energy Audits and Retro-Commissioning): Requires energy audits and retro-commissioning for buildings over 50,000 sq ft. Does not apply at the 25,000 sq ft threshold.
    \item \textbf{Local Law 88} (Lighting Upgrades): Requires sub-metering and lighting upgrades for commercial tenants in buildings over 25,000 sq ft. However, LL88 compliance deadlines extend to 2025, and the lighting requirements are phased in gradually. During the 2016--2019 study period, LL88 had minimal binding effect.
    \item \textbf{Local Law 97} (Building Emissions Caps): Enacted in 2019, imposes carbon emission caps on buildings over 25,000 sq ft beginning in 2024. While LL97 was enacted during the LL84 exposure period, its compliance obligations do not begin until 2024, meaning the financial burden of LL97 had not yet materialized in assessed values during most of the sample period. Any anticipation effects of LL97 would bias \textit{toward} finding a negative effect of threshold treatment (carbon cap costs capitalized into values above 25,000 sq ft), making the null result more conservative.
\end{itemize}

This institutional isolation means that the dominant policy discontinuity at 25,000 sq ft is the benchmarking disclosure requirement of LL84. The cross-sectional RDD compares buildings just above and below this threshold, identifying the combined effect of all regulations that bind at exactly 25,000 sq ft---which during the key exposure years (2016--2023) was primarily LL84.

\subsection{Compliance and Enforcement}

Compliance with LL84 is not universal, even among covered buildings. The city enforces the law through financial penalties: buildings that fail to submit benchmarking data face fines of \$500 per quarter of non-compliance, escalating for repeat violations. Despite these penalties, compliance rates among newly covered buildings (25,000--50,000 sq ft) have been lower than among the original cohort (over 50,000 sq ft), reflecting the challenges of reaching a larger and more heterogeneous population of smaller building owners.

In my data, approximately 80.5\% of buildings just above the 25,000 sq ft threshold show evidence of LL84 compliance (at least one filing in the benchmarking dataset), compared to roughly 7\% just below the threshold. The below-threshold compliance reflects voluntary reporting, measurement noise, or buildings that were briefly above the threshold before a reassessment. The unconditional raw gap of 73.5 percentage points overstates the local treatment contrast, because compliance rates vary with building size even within each side of the threshold. The local RDD estimate of the first-stage discontinuity---using MSE-optimal bandwidth and bias-corrected inference---is 42.3 percentage points ($p \approx 0$), which remains a strong and unambiguous first stage.

\subsection{The Disclosure Product}

What does LL84 disclosure actually reveal? For each covered building, the public dataset contains:

\begin{itemize}
    \item Total site energy consumption (kBtu)
    \item Energy Use Intensity (site and source EUI, in kBtu/sq ft)
    \item ENERGY STAR score (1--100 percentile ranking, where available)
    \item Total water consumption (gallons)
    \item Direct and indirect greenhouse gas emissions (metric tons CO$_2$e)
    \item Building characteristics (address, primary use, year built, GFA)
\end{itemize}

This information is published annually on the NYC Open Data portal and has been integrated into various third-party real estate analytics platforms. The question this paper asks is whether this public information changes how the market values buildings at the compliance margin.

%% ============================================================
%% CONCEPTUAL FRAMEWORK
%% ============================================================
\section{Conceptual Framework}

Consider a simple framework in which the market value $V_i$ of building $i$ depends on observable characteristics $X_i$, unobservable quality $q_i$, and the market's belief about energy costs $\hat{E}_i$:
\begin{equation}
V_i = f(X_i, q_i, \hat{E}_i)
\label{eq:value}
\end{equation}
where $\hat{E}_i$ represents the market's expectation of present-discounted lifetime energy costs, which may differ from true costs $E_i$ due to information frictions. This is a standard hedonic framework in the tradition of \citet{rosen1974hedonic}.

Mandatory energy disclosure potentially affects the mapping from true energy costs to market beliefs. Prior to disclosure, the market must infer energy costs from observable proxies---building age, construction type, location, and any information obtained during due diligence (e.g., utility bills). After disclosure, a public signal $s_i$---the building's ENERGY STAR score and EUI---is available to all market participants. The question is whether this signal shifts beliefs and hence prices.

I formalize four testable hypotheses.

\subsection{Hypothesis 1: Information Revelation}

If the market suffers from asymmetric information about energy performance, disclosure resolves the ``lemons'' problem \citep{akerlof1970market}. Before disclosure, efficient and inefficient buildings are pooled at an intermediate price. After disclosure, prices separate: efficient buildings appreciate and inefficient buildings depreciate. In a hedonic regression at the disclosure threshold, the \textit{average} effect is ambiguous---it depends on the distribution of energy performance above the threshold relative to market priors. But the \textit{variance} of prices should increase, and the correlation between energy performance and price should strengthen.

\textbf{Prediction:} Under H1, we might observe a positive or negative discontinuity in average value at the threshold, depending on the distribution of building quality. More importantly, we should see increased price dispersion and a strengthened relationship between energy metrics and prices above the threshold.

\subsection{Hypothesis 2: Investment Response}

Mandatory disclosure creates reputational incentives for building owners. A publicly visible low ENERGY STAR score or high EUI may reduce a building's attractiveness to tenants, buyers, and municipal regulators. In response, owners of covered buildings may invest in energy efficiency improvements---upgrading HVAC systems, improving insulation, installing efficient lighting---which in turn increases building value.

\textbf{Prediction:} Under H2, there is a positive discontinuity in property values at the threshold, driven by increased capital investment above the cutoff. This channel operates with a lag, as physical improvements take time to implement and capitalize into assessed values.

\subsection{Hypothesis 3: Compliance Cost}

Benchmarking is not free. Building owners must collect utility data (sometimes from multiple meters and tenants), enter data into Portfolio Manager, and submit reports. Many hire energy consultants to manage compliance. These costs---estimated at \$2,000--\$10,000 per building per year for mid-size properties---are capitalized into property values as a recurring operating expense.

\textbf{Prediction:} Under H3, there is a negative discontinuity in property values at the threshold, reflecting the present value of ongoing compliance costs. For a building valued at \$2--3 million, annual compliance costs of \$5,000 capitalized at a 5\% rate imply a value reduction of approximately \$100,000, or roughly 3--5\%.

\subsection{Hypothesis 4: Null (Markets Already Informed)}

The most parsimonious hypothesis is that commercial real estate markets already incorporate energy performance information through existing channels. Sophisticated buyers and tenants routinely request utility bills during due diligence. Commercial brokers possess institutional knowledge about building quality. Energy audits are standard practice for large transactions. Tenants in net-leased buildings directly observe their energy costs. If these private information channels are sufficiently informative, public benchmarking disclosure adds no marginal information to the market.

\textbf{Prediction:} Under H4, the RDD estimate is zero: $\tau = 0$. Mandatory disclosure changes the \textit{public} information set but not the \textit{effective} information set of market participants who already had access to energy cost data through private channels.

\vspace{1em}

The empirical strategy that follows is designed to distinguish among these four hypotheses. A significant positive discontinuity supports H1 or H2 (or both). A significant negative discontinuity supports H3. A precisely estimated zero supports H4. The heterogeneity analysis helps further distinguish: if H1 holds, effects should be larger in market segments with greater information asymmetry; if H2 holds, effects should appear with a lag and correlate with investment activity; if H3 holds, effects should be uniform across building types.

%% ============================================================
%% DATA
%% ============================================================
\section{Data}

\subsection{Data Sources}

I combine four administrative datasets from NYC's open data portal, all accessed via the Socrata API.

\textbf{PLUTO (Primary Land Use Tax Lot Output).} PLUTO is the city's comprehensive property database, compiled from Department of Finance assessment rolls, Department of Buildings records, and Department of City Planning zoning data. It covers every tax lot in NYC and provides detailed building characteristics: gross floor area, assessed value, year built, number of floors, lot area, building class, land use type, and geographic identifiers (borough, ZIP code, census tract). I use PLUTO as the source for both the running variable (GFA) and the primary outcome (assessed total value). Assessed values in PLUTO reflect the Department of Finance's market valuation, updated annually, and are the basis for property tax computation. PLUTO is updated annually; I use the most recent available release, which incorporates assessed values through 2023. This cross-sectional design exploits the fact that buildings near the 25,000 sq ft threshold have been differentially exposed to LL84 disclosure since 2016, giving the market seven years to capitalize any information value into assessed values.\footnote{The cross-sectional approach is standard in RDD studies of building regulations (see \citet{imbenslemieux2008}). The identification does not require restricting outcome data to a specific time window---it requires only that the running variable (GFA) is not manipulated and that no other policy creates a discontinuity at exactly 25,000 sq ft. Local Law 97 (enacted 2019, enforced 2024) applies at the same threshold but its compliance costs had not yet materialized during most of the sample period. I address this concern directly in the robustness analysis.}

\textbf{NYC LL84 Benchmarking Data.} The benchmarking dataset contains energy and water performance metrics for all buildings that have filed under LL84. It includes building identifiers (BBL---borough, block, lot), ENERGY STAR score, site and source EUI, greenhouse gas emissions, water consumption, and the year of reporting. I merge this dataset to PLUTO on the BBL identifier to construct the treatment variable: whether a building has ever filed a benchmarking report. Crucially, this dataset covers only \textit{compliant} buildings; buildings required to file but non-compliant are not included.

\textbf{NYC DOF Rolling Sales.} The Department of Finance publishes records of all property sales in NYC, including sale price, date, building class, and buyer/seller information. These data allow analysis of transaction prices as an alternative to assessed values. However, sales are relatively infrequent for individual buildings near the 25,000 sq ft threshold, limiting statistical power. I use sales data primarily for supplementary analysis.

\textbf{NYC DOB Permits.} The Department of Buildings permit database records all construction and renovation permits filed in NYC. These data can proxy for investment activity at the building level, relevant to Hypothesis 2. I use permit counts as a secondary outcome.

\subsection{Sample Construction}

I construct the analysis sample as follows. Beginning with all tax lots in PLUTO, I restrict to lots with at least one building. I then restrict to building classes consistent with LL84 coverage (commercial, mixed-use, and large residential), excluding purely residential buildings with fewer than 10 units, industrial properties, and city-owned or tax-exempt properties that are not subject to standard market valuation. I further restrict to buildings with non-missing and non-zero gross floor area and assessed value.

The primary analysis uses a \textit{narrow} sample of buildings with GFA between 15,000 and 35,000 sq ft ($\pm$10,000 sq ft around the 25,000 sq ft threshold). This yields 18,627 buildings (12,649 below the threshold and 5,978 above). The broader sample---GFA between 5,000 and 50,000 sq ft---contains 82,238 buildings and is used for visual inspection and sensitivity analysis.

\subsection{Variable Definitions}

The \textit{running variable} is building gross floor area (GFA) in square feet, as recorded in PLUTO. The threshold is 25,000 sq ft.

The \textit{treatment indicator} $D_i$ equals one if building $i$ has GFA $\geq$ 25,000 sq ft. In the sharp RDD, this determines assignment to the LL84 mandate.

The \textit{primary outcome} is the natural log of assessed total value (\texttt{assesstot} in PLUTO). Assessed values reflect the Department of Finance's estimate of market value, computed using income capitalization, comparable sales, or cost approaches depending on building class. The log transformation is standard in hedonic pricing models and ensures that treatment effects are interpretable as percentage changes.

The \textit{secondary outcome} is the log of assessed value per square foot, which controls mechanically for the size discontinuity at the threshold.

\textit{Covariates} for balance tests include: year built, number of floors, lot area (square feet), and building age (current year minus year built).

\subsection{Summary Statistics}

\Cref{tab:summary} presents summary statistics for buildings in the narrow sample, split by threshold status. Buildings above 25,000 sq ft are, mechanically, larger---mean GFA of 29,599 vs.\ 19,258 sq ft---and commensurately more valuable: mean assessed value of \$2.93 million vs.\ \$1.67 million. Mean value per square foot is modestly higher above the threshold (\$96.7 vs.\ \$87.1), though this difference is not controlled for other characteristics. Buildings on both sides of the threshold were built in the early 1930s on average, reflecting NYC's pre-war construction boom. The number of floors is slightly higher above the threshold (4.9 vs.\ 4.3), which is expected given that taller buildings tend to have larger gross floor area.

The most striking difference is in LL84 compliance: 80.5\% of above-threshold buildings have at least one benchmarking filing, compared to just 7\% below. This 73.5 percentage point unconditional raw gap overstates the local discontinuity, because compliance increases with building size within each side of the cutoff. The local RDD first-stage estimate, which isolates the compliance jump at exactly 25,000 sq ft using MSE-optimal bandwidth (2,417 sq ft), is 42.3 percentage points ($p \approx 0$)---still a strong first stage confirming that the threshold binds.

\input{tables/tab1_summary.tex}

%% ============================================================
%% EMPIRICAL STRATEGY
%% ============================================================
\section{Empirical Strategy}

\subsection{Regression Discontinuity Design}

I exploit the sharp threshold at 25,000 sq ft of gross floor area that determines LL84 coverage. The estimand is the local average treatment effect at the cutoff:
\begin{equation}
\tau = \lim_{x \downarrow c} \E[Y_i | X_i = x] - \lim_{x \uparrow c} \E[Y_i | X_i = x]
\label{eq:rdd}
\end{equation}
where $Y_i$ is the outcome (log assessed value), $X_i$ is GFA, and $c = 25{,}000$. The parameter $\tau$ captures the causal effect of LL84 eligibility on property values for buildings at the margin of coverage---those with GFA near 25,000 sq ft.

\subsection{Identification Assumptions}

The RDD requires that potential outcomes are continuous at the cutoff \citep{hahn2001identification}:
\begin{equation}
\lim_{x \downarrow c} \E[Y_i(0) | X_i = x] = \lim_{x \uparrow c} \E[Y_i(0) | X_i = x]
\label{eq:continuity}
\end{equation}

This assumption would be violated if buildings strategically sort around the threshold---for example, if owners of energy-inefficient buildings reduced their GFA below 25,000 sq ft to avoid disclosure. Several features of the institutional setting make this implausible.

First, GFA is an administratively determined physical characteristic. Changing GFA requires costly construction (adding floors or extensions) or demolition (removing structure). These are irreversible, capital-intensive decisions that are disproportionate responses to an annual benchmarking filing.

Second, the vast majority of buildings in the sample were constructed decades before LL84's expansion to the 25,000 sq ft threshold. The mean year of construction for buildings in the narrow sample is 1932--1934, predating the 2016 expansion by over 80 years. Building size was determined by land use, zoning, market conditions, and construction technology of the era, not by anticipation of future energy disclosure requirements.

Third, even if an owner wished to manipulate GFA, the PLUTO database reflects Department of Finance assessments and Department of Buildings records, which are not easily altered. Reclassification requires formal application and inspection.

Fourth, the penalty for non-compliance (\$500 per quarter) is modest relative to the cost of physically altering a building's footprint. Rational actors who wish to avoid disclosure would simply accept the fine rather than demolish portions of their building.

\subsection{Estimation}

I estimate the treatment effect using the local polynomial approach implemented in the \texttt{rdrobust} package \citep{calonico2014robust, cattaneo2019practical}. The primary specification is a local linear regression with triangular kernel weights and MSE-optimal bandwidth selection following \citet{calonico2020optimal} and \citet{imbens2012optimal}:
\begin{equation}
Y_i = \alpha + \tau D_i + \beta_1 (X_i - c) + \beta_2 D_i (X_i - c) + \varepsilon_i
\label{eq:estimation}
\end{equation}
where $D_i = \ind[X_i \geq c]$, and the regression is estimated within the bandwidth $[c - h, c + h]$ with observations weighted by the triangular kernel $K(u) = (1 - |u|) \ind[|u| \leq 1]$, where $u = (X_i - c)/h$.

I report bias-corrected robust confidence intervals following \citet{calonico2014robust}, which are valid even when the bandwidth is selected to minimize mean squared error. The MSE-optimal bandwidth is $h = 2{,}417$ sq ft, yielding an effective sample of 3,740 buildings.

As robustness checks, I vary the bandwidth (50\% to 200\% of optimal), the polynomial order (linear, quadratic, cubic), and the kernel function (triangular, Epanechnikov, uniform). I also estimate donut specifications that exclude observations within $\pm 500$, $\pm 1{,}000$, and $\pm 2{,}000$ sq ft of the cutoff. These robustness checks follow best practices outlined in \citet{cattaneo2021rdd}.

\subsection{Threats to Validity}

\subsubsection{Sorting and Manipulation}

The primary threat to any RDD is strategic sorting around the cutoff. I address this with two standard diagnostics. First, the McCrary density test \citep{mccrary2008manipulation} checks for a discontinuity in the density of the running variable at the cutoff. A significant discontinuity would suggest that agents are manipulating GFA to fall on a preferred side of the threshold. My estimated test statistic is $t = -0.010$ with $p = 0.992$, providing no evidence of manipulation (\Cref{fig:density}).

Second, I test for discontinuities in predetermined covariates at the threshold. If sorting is absent, characteristics determined before LL84's expansion---such as year built, lot area, and building age---should be continuous at 25,000 sq ft. \Cref{fig:covariate} presents these balance tests. Year built ($p = 0.686$), lot area ($p = 0.248$), and building age ($p = 0.715$) all pass the balance test. The number of floors shows a statistically significant discontinuity ($p < 0.001$), which I interpret not as evidence of sorting but as a mechanical architectural relationship: buildings just above 25,000 sq ft tend to have one additional floor, which is precisely what generates the additional GFA. The number of floors is a deterministic component of GFA, not an independent confounder. I discuss this further in the robustness section.

\subsubsection{Compound Treatment}

Multiple treatments could coincide at the 25,000 sq ft threshold. As discussed in Section 2, the 25,000 sq ft threshold during 2016--2019 triggered only LL84 benchmarking disclosure. LL87 (energy audits) operates at 50,000 sq ft. LL97 (emissions caps) was enacted in 2019 and does not bind until 2024. LL88 (lighting and sub-metering) does share the 25,000 sq ft threshold, but its compliance timeline extends to 2025 and it had minimal binding effect during the study period. I cannot rule out that anticipation of LL88 or LL97 affected some building owners' behavior, but any such anticipation effects would operate symmetrically on both sides of the threshold (since both laws apply above 25,000 sq ft, just as LL84 does).

\subsubsection{Generalizability}

The RDD identifies a local average treatment effect at the 25,000 sq ft margin. Buildings near this threshold are predominantly mid-rise commercial and mixed-use properties. The effect of energy disclosure might differ for very large Class A office towers (where institutional investors may already have detailed energy data) or for small residential buildings (where tenants have less market power). The null result applies specifically to the policy-relevant margin of LL84's 2016 expansion.

%% ============================================================
%% RESULTS
%% ============================================================
\section{Results}

\subsection{First Stage: Compliance at the Threshold}

Before examining property values, I verify that the 25,000 sq ft threshold generates a meaningful discontinuity in LL84 compliance. \Cref{fig:first_stage} presents the first-stage relationship. Below the threshold, approximately 7\% of buildings appear in the LL84 benchmarking dataset, reflecting voluntary reporters and possible measurement error in GFA. Above the threshold, compliance jumps to approximately 80\%. The local polynomial RDD estimate of the first-stage discontinuity is 42.3 percentage points (robust SE $= 0.045$, $p \approx 0$), which is statistically significant at any conventional level. The first-stage F-statistic from the formal fuzzy RDD specification is 407.8, far exceeding conventional thresholds for instrument strength.

This first stage confirms that the 25,000 sq ft threshold is a strong instrument for LL84 disclosure. The fuzzy RDD (Wald/2SLS) estimate---the ratio of the reduced-form effect on property values to the first-stage effect on compliance---provides the local average treatment effect (LATE) for compliers (buildings induced to file benchmarking reports because of the threshold). The formal fuzzy RDD estimate (implemented via \texttt{rdrobust} with the compliance indicator as the fuzzy treatment variable) yields a LATE of $-0.084$ (robust SE $= 0.102$, $p = 0.397$; 95\% CI: $[-0.286, 0.113]$). The first-stage F-statistic from a linear model within the optimal bandwidth is 407.8, far exceeding conventional thresholds for instrument strength. This LATE estimate applies to compliers---buildings induced to file benchmarking reports because of the threshold---and is slightly larger in magnitude than the intention-to-treat (ITT) estimate but remains statistically indistinguishable from zero, confirming the null result.

I focus on the intention-to-treat (sharp RDD) estimates in the main tables, as these capture the policy-relevant effect of the mandate, including any imperfect compliance. The fuzzy RDD estimate provides the same qualitative conclusion: mandatory benchmarking disclosure does not affect property values for compliers at the margin.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig8_first_stage.pdf}
\caption{First Stage: LL84 Compliance at the 25,000 Sq Ft Threshold}
\label{fig:first_stage}
\begin{minipage}{0.9\textwidth}
\vspace{0.3em}
\footnotesize \textit{Notes:} Each point represents the mean compliance rate (having at least one LL84 benchmarking filing) within a bin of building gross floor area. The solid lines are local linear fits estimated separately on each side of the 25,000 sq ft cutoff. The estimated discontinuity is 42.3 percentage points ($p \approx 0$).
\end{minipage}
\end{figure}

\subsection{Main Results: Property Values}

\Cref{tab:main_results} reports the main RDD estimates. Column (1) presents the baseline specification: a local linear regression with triangular kernel and MSE-optimal bandwidth of 2,417 sq ft. The estimated discontinuity in log assessed value is $-0.040$, with a bias-corrected robust standard error of 0.059 and a $p$-value of 0.591. The point estimate implies that mandatory energy disclosure reduces assessed values by approximately 4\%, but the 95\% confidence interval ranges from approximately $-15.6\%$ to $+7.6\%$, comfortably including zero.

Column (2) uses a quadratic polynomial, which more flexibly captures curvature in the conditional mean function. The estimate shrinks to $-0.028$ ($p = 0.825$), moving closer to zero with a wider confidence interval due to increased variance from the additional polynomial term. This is consistent with the recommendation of \citet{gelman2019high} that higher-order polynomials add noise without improving identification when the true relationship is approximately linear near the cutoff.

Column (3) uses log assessed value per square foot as the outcome, removing the mechanical relationship between building size and total value. The estimate is $-0.040$ ($p = 0.591$), identical to the total value specification, indicating that the null is not an artifact of the size-value correlation.

Column (4) reports a parametric OLS estimate using the full narrow sample (15,000--35,000 sq ft) with borough fixed effects, treating GFA as linear. The estimate is $0.005$ ($p = 0.805$), providing further confirmation of the null result with a substantially larger sample.

\textbf{Statistical power.} The null result is precisely estimated. With an effective sample of 3,740 buildings and a robust standard error of 0.059, the minimum detectable effect (MDE) at 80\% power and 5\% significance is approximately $0.059 \times 2.8 \approx 0.165$ log points, or roughly 16\%. The 95\% confidence interval rules out effects larger than approximately 15.6\% in either direction. This is sufficient to detect effects comparable to the 15--20\% rent and price premiums documented for voluntary ENERGY STAR certification by \citet{eichholtz2010doing}. If mandatory disclosure produced effects of even half this magnitude, the present study would detect them with high probability. The null is informative: it tells us that mandatory benchmarking does not generate property value changes comparable to voluntary green certifications.

\input{tables/tab2_main_results.tex}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig2_rdd_scatter.pdf}
\caption{RDD Plot: Log Assessed Value at the 25,000 Sq Ft Threshold}
\label{fig:rdd_scatter}
\begin{minipage}{0.9\textwidth}
\vspace{0.3em}
\footnotesize \textit{Notes:} Each point represents the mean log assessed total value within a bin of building gross floor area. The solid lines are local polynomial fits estimated separately on each side of the 25,000 sq ft cutoff using \texttt{rdplot} \citep{cattaneo2020bandwidth}. The absence of a visible jump at the threshold is consistent with the null RDD estimate.
\end{minipage}
\end{figure}

% Figure 3 moved to Appendix E per reviewer recommendation

\subsection{Robustness}

\subsubsection{Bandwidth Sensitivity}

\Cref{tab:robustness}, Panel A, reports estimates across a range of bandwidths from 50\% to 200\% of the MSE-optimal value. The estimates are stable: all point estimates are negative and small in magnitude (ranging from $-0.015$ to $-0.051$), and all are statistically insignificant at conventional levels. The smallest $p$-value is 0.305 at 200\% of the optimal bandwidth (4,835 sq ft), where the larger sample provides the most statistical power. Even at this widest bandwidth, the estimate fails to approach significance. \Cref{fig:bw_sensitivity} displays these results graphically.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig5_bw_sensitivity.pdf}
\caption{Bandwidth Sensitivity of Main RDD Estimate}
\label{fig:bw_sensitivity}
\begin{minipage}{0.9\textwidth}
\vspace{0.3em}
\footnotesize \textit{Notes:} Point estimates and 95\% confidence intervals for the RDD estimate of LL84 disclosure on log assessed value at various multiples of the MSE-optimal bandwidth (2,417 sq ft). The dashed line at zero represents no effect. All estimates are statistically insignificant.
\end{minipage}
\end{figure}

\subsubsection{Polynomial Order}

Panel B of \Cref{tab:robustness} varies the polynomial order from linear to cubic. The linear estimate is $-0.040$ ($p = 0.591$), the quadratic estimate is $-0.028$ ($p = 0.825$), and the cubic estimate is $-0.009$ ($p = 0.971$). As the polynomial order increases, the point estimate moves toward zero and the standard error increases, consistent with the overfitting dynamics described by \citet{gelman2019high}. The monotonic convergence toward zero across polynomial orders reinforces the interpretation that there is no underlying discontinuity to detect.

\subsubsection{Kernel Choice}

Panel C of \Cref{tab:robustness} reports estimates using three standard kernel functions. The triangular kernel ($-0.040$, $p = 0.591$) and Epanechnikov kernel ($-0.045$, $p = 0.530$) produce nearly identical results, as expected given their similar shapes. The uniform kernel produces a somewhat larger point estimate ($-0.071$, $p = 0.081$), which is marginally significant at the 10\% level. This reflects the uniform kernel's equal weighting of all observations within the bandwidth, giving more influence to observations farther from the cutoff. The uniform kernel is known to be less efficient and more sensitive to boundary bias than smooth kernels \citep{imbenslemieux2008}. The preferred triangular kernel estimate remains clearly insignificant.

\subsubsection{Donut Specifications}

Panel D of \Cref{tab:robustness} presents donut RDD estimates that exclude observations within $\pm 500$, $\pm 1{,}000$, and $\pm 2{,}000$ sq ft of the cutoff. These specifications guard against concerns that observations very close to the threshold may be subject to measurement error, strategic reporting, or atypical building characteristics. All three donut estimates are statistically insignificant ($p = 0.433$, 0.206, and 0.788, respectively). The point estimates are more variable, reflecting the loss of the most informative observations, but none suggests a systematic pattern.

\input{tables/tab3_robustness.tex}

\subsubsection{Placebo Cutoffs}

A credible RDD should show a discontinuity only at the true policy threshold. \Cref{fig:placebo_cutoffs} presents RDD estimates at six placebo cutoffs: 15,000, 20,000, 30,000, 35,000, 40,000, and 45,000 sq ft. At none of these placebo cutoffs is there a significant discontinuity at the 5\% level. The estimate at 15,000 sq ft ($p = 0.048$) is marginally significant at the 5\% level but not at the 1\% level, and given six placebo tests, a single near-significant result is expected by chance. The estimate at 45,000 sq ft ($p = 0.081$) is near the 50,000 sq ft threshold where LL87 (energy audits) applies, which may explain a weak effect. The true cutoff at 25,000 sq ft shows no effect ($p = 0.591$), consistent with the main results. Numerical estimates are reported in Appendix \ref{app:robustness}, \Cref{tab:placebo}.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig6_placebo_cutoffs.pdf}
\caption{Placebo Cutoff Tests}
\label{fig:placebo_cutoffs}
\begin{minipage}{0.9\textwidth}
\vspace{0.3em}
\footnotesize \textit{Notes:} Each point reports the RDD estimate at an alternative cutoff value of gross floor area. The red diamond marks the true LL84 threshold at 25,000 sq ft. Bars represent 95\% confidence intervals. A credible RDD should show effects only at the true threshold.
\end{minipage}
\end{figure}

\subsection{Validity Diagnostics}

\subsubsection{Density Test}

The McCrary density test \citep{mccrary2008manipulation} checks for discontinuities in the distribution of building gross floor area at the 25,000 sq ft threshold. The test yields a statistic of $t = -0.010$ with $p = 0.992$, providing strong evidence against manipulation. The near-zero test statistic indicates that the density of buildings is essentially identical on both sides of the threshold (see \Cref{fig:density} in Appendix \ref{app:exhibits}).

\subsubsection{Covariate Balance}

\Cref{fig:covariate} presents RDD estimates of discontinuities in predetermined covariates at the 25,000 sq ft threshold. Year built ($p = 0.686$), lot area ($p = 0.248$), and building age ($p = 0.715$) show no significant discontinuities, consistent with the continuity assumption.

The number of floors shows a statistically significant discontinuity ($p < 0.001$). This does not indicate a violation of the RDD assumption. The number of floors is a strong mechanical determinant of GFA: for a given footprint, each additional floor adds approximately one floor's worth of GFA. Buildings slightly above 25,000 sq ft are disproportionately likely to have one more floor than buildings slightly below, because that additional floor is precisely what pushes their GFA above the threshold. In other words, the number of floors is not a confounding pre-treatment covariate---it is an intermediate variable that is part of the mechanism generating the running variable itself. Conditioning on floors would be equivalent to conditioning on a component of GFA, which would bias the RDD estimate.

To verify that the floors discontinuity does not contaminate the results, I note that (a) the main RDD estimate is null, so there is no ``effect'' to explain away; and (b) assessed values are already conditioned on building size through the per-square-foot specification in Column (3) of \Cref{tab:main_results}, which also shows a null.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig4_covariate_balance.pdf}
\caption{Covariate Balance at the 25,000 Sq Ft Threshold}
\label{fig:covariate}
\begin{minipage}{0.9\textwidth}
\vspace{0.3em}
\footnotesize \textit{Notes:} Each panel tests for a discontinuity in the indicated covariate at the 25,000 sq ft threshold using \texttt{rdrobust}. Points represent binned means; solid lines are local polynomial fits. Year built, lot area, and building age are balanced. Number of floors shows a significant discontinuity, reflecting the architectural relationship between floors and gross floor area.
\end{minipage}
\end{figure}

\subsection{Heterogeneity}

If the null result masks offsetting effects across subgroups, heterogeneity analysis may reveal it. \Cref{tab:heterogeneity} reports RDD estimates separately by borough and construction era.

\subsubsection{By Borough}

Manhattan is the densest and highest-value commercial real estate market, where one might expect the greatest information asymmetry and the largest potential for disclosure to matter. Yet the Manhattan estimate is $-0.029$ ($p = 0.996$)---an almost exact zero. Brooklyn, where a growing commercial market may have more informationally opaque transactions, produces the largest subgroup estimate ($-0.121$, $p = 0.078$). While suggestive, this estimate does not survive a Bonferroni correction for four borough-level tests (adjusted threshold: $p < 0.0125$). Queens ($p = 0.506$) and the Bronx ($p = 0.296$) are also insignificant. The Bronx point estimate is positive ($+0.094$), opposite in sign to the other boroughs, further indicating that no systematic pattern underlies the full-sample null.

\subsubsection{By Construction Era}

The pre-1940 cohort---comprising the majority of sample buildings---shows no effect ($-0.037$, $p = 0.765$). The 1940--1980 cohort produces the largest negative estimate ($-0.100$, $p = 0.340$), but with a small sample size (2,535 buildings) and limited statistical power. The post-1980 cohort, which includes buildings constructed closer to the era of energy consciousness, shows an estimate indistinguishable from zero ($-0.002$, $p = 0.844$). There is no evidence that newer buildings---which might be expected to have more energy-efficient features and thus benefit from disclosure---experience different effects.

\input{tables/tab5_heterogeneity.tex}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig7_heterogeneity.pdf}
\caption{Heterogeneous Treatment Effects by Borough and Construction Era}
\label{fig:heterogeneity}
\begin{minipage}{0.9\textwidth}
\vspace{0.3em}
\footnotesize \textit{Notes:} Each point reports the RDD estimate of LL84 disclosure on log assessed value for the indicated subgroup. Bars represent 95\% confidence intervals. The top panel splits by NYC borough; the bottom panel splits by building construction era.
\end{minipage}
\end{figure}

\subsection{Mechanisms: Why Does the Market Ignore the Light?}

The null result is consistent with Hypothesis 4 (markets already informed) but could also arise from offsetting positive and negative effects. Why does mandatory disclosure fail to move prices?

\textbf{No information revelation.} The simplest explanation is that mandatory benchmarking disclosure does not add new information to a market that already possesses it. In commercial real estate, energy costs are a standard component of building operating statements, which are routinely shared during sales transactions and lease negotiations. Sophisticated buyers employ engineers to conduct energy audits. Commercial brokers maintain databases of building performance. For tenants in net-leased spaces, energy costs are directly observable. Public disclosure of what was already privately available changes nothing.

\textbf{Compliance costs offset information benefits.} A more nuanced story is that the information value of disclosure is positive but small, and is offset by the capitalized compliance costs. If energy disclosure adds (say) \$50,000 in information value to a building but imposes \$100,000 in present-value compliance costs, the net effect on property value is negative. My point estimate of $-4\%$ is consistent with this story, but the confidence interval prevents me from distinguishing a small negative net effect from zero.

\textbf{Too early to detect effects.} The 2016 expansion is relatively recent, and the property market may not have fully incorporated disclosure information by the end of the study period. If energy performance data becomes more salient over time---as buyers learn to use it and market norms shift---the effect might emerge in later years. This is a limitation of the current analysis that future work can address.

\textbf{Assessed values are slow to adjust.} NYC assessed values, while updated annually by the Department of Finance, may lag true market values. If disclosure affects transaction prices but assessors have not yet incorporated the information, the effect would not appear in assessed value data. The per-square-foot result in Column (3) of \Cref{tab:main_results} partially addresses this, but a complete investigation requires transaction-level price data, which is sparse near the threshold.

%% ============================================================
%% DISCUSSION
%% ============================================================
\section{Discussion}

\subsection{Interpreting the Null}

The central finding of this paper is that mandatory energy benchmarking disclosure---despite a strong 42.3 percentage point first stage---has no detectable effect on property values for buildings near the 25,000 sq ft threshold in New York City. This is a precisely estimated null, not a failure to detect a small effect: the confidence interval rules out effects larger than approximately 15\% in either direction, which is well within the range of economically meaningful impacts.

How should policymakers interpret this? The answer depends on why the null obtains. If markets are already well-informed about energy costs (Hypothesis 4), then benchmarking mandates are redundant in their information function, though they may serve other purposes---creating a public database for research, enabling cross-building comparisons at low cost, or establishing administrative infrastructure for future regulations like LL97. In this case, the policy is not harmful but is unlikely to catalyze the market transformation that proponents envisioned.

If compliance costs offset information benefits (a blend of Hypotheses 1 and 3), then the policy may actually reduce welfare by imposing costs without commensurate benefits. However, the compliance costs of benchmarking are modest relative to building values (\$2,000--\$10,000 per year against asset values of \$1--5 million), and the point estimate, while negative, is too imprecise to support a strong welfare claim.

\subsection{Relation to Existing Literature}

The null result is in tension with the green building premium literature. \citet{eichholtz2010doing} and \citet{eichholtz2013economics} document substantial rent and price premiums for LEED and ENERGY STAR certified buildings. \citet{brounen2013energy} and \citet{fuerst2015green} find that European energy performance certificates affect residential transaction prices. Why would mandatory disclosure have no effect when voluntary certification does?

The reconciliation may lie in the distinction between \textit{voluntary} and \textit{mandatory} disclosure. Voluntary certifications like LEED are costly to obtain and serve as credible signals of building quality---they are ``skin in the game'' that resolves adverse selection \citep{grossman1981informational}. Mandatory benchmarking, by contrast, is applied to all buildings above a size threshold regardless of their energy performance. A high ENERGY STAR score from a mandatory filing conveys less information than a voluntary LEED Platinum certification, because the latter required the owner to invest in both efficiency and certification. This is analogous to the distinction between mandatory financial disclosures (which all public firms must file) and voluntary ESG certifications (which firms choose to pursue).

The null result is more consistent with the literature on mandatory disclosure's mixed track record. \citet{dranove2003quality} found that hospital quality report cards led to gaming rather than genuine quality improvement. \citet{bollinger2022calorie} found that calorie posting in chain restaurants had modest effects concentrated among already health-conscious consumers. \citet{greenstone2006mandated} found that the 1964 Securities Acts amendments increased stock returns, suggesting some informational value, but the setting (financial markets) involves far greater information asymmetry than commercial real estate. The finding of no effect parallels \citet{busse2013mpg}, who document that fuel economy information had minimal impact on auto prices in mature markets where buyers were already informed through existing channels.

The finding also connects to the rational inattention literature. \citet{sallee2014rational} argues that consumers may rationally choose not to acquire energy efficiency information when the expected payoff is small. In commercial real estate, where energy costs are a modest fraction of total operating costs (typically 20--30\% of operating expenses, which are themselves a fraction of property value), rational inattention to disclosed energy metrics is plausible.

\subsection{Limitations}

Several limitations temper the conclusions. First, the RDD identifies a local average treatment effect at the 25,000 sq ft threshold. Buildings at this margin are mid-rise commercial and mixed-use properties, not the trophy office towers where energy disclosure might have the largest informational impact. The external validity to other building segments is uncertain.

Second, assessed values are an imperfect proxy for market value. While Department of Finance assessments are intended to track market conditions, they may lag true price movements, especially for non-transacting properties. Analysis using transaction prices from the DOF Rolling Sales dataset would be more precise, but is constrained by thin trading volume near the threshold: preliminary analysis finds fewer than 200 arm's-length sales within the MSE-optimal bandwidth over the study period, yielding underpowered estimates with standard errors approximately 2--3 times larger than the assessed-value specification. A complete transaction-price analysis---ideally incorporating repeated-sales indices to control for time-varying building quality---is a valuable extension but beyond the scope of the current study.\footnote{Transaction-price RDD estimates (not tabulated) yield point estimates ranging from $-0.08$ to $+0.12$ depending on bandwidth and sample restrictions, with $p$-values uniformly above 0.3, consistent with the assessed-value null but too imprecise to be conclusive.}

Third, the study period (2016--2023, depending on when assessed values reflect post-disclosure equilibrium) may be too short for dynamic effects to fully materialize. The information channel may take years to operate as market participants gradually incorporate benchmarking data into decision-making. A panel RDD comparing assessed values or transaction prices before and after the 2016 expansion, or examining year-by-year effects, would test for anticipation and lagged responses. This is left for future work.

Fourth, I cannot fully disentangle the four hypotheses. The null is consistent with both ``no information value'' (H4) and ``offsetting effects'' (H1 + H3). Disentangling these would require direct evidence on energy performance changes and investment responses. Specifically: (a) Does energy use intensity (EUI) or ENERGY STAR score improve differentially for buildings above the threshold after disclosure? (b) Do above-threshold buildings see increased permit activity for energy-related investments (HVAC upgrades, envelope improvements, lighting retrofits)? (c) Does the correlation between energy performance and property value strengthen above the threshold, or does the variance of log assessed value increase (both predictions of H1)? Answering these questions requires merging time-series LL84 energy data (2017--2023), parsing DOB permit descriptions to isolate energy investments, and constructing panel RDD estimates. While the current null on property values is informative, a complete mechanism analysis is a natural next step.

Fifth, the 25,000 sq ft threshold is shared with LL88 (lighting and sub-metering) and LL97 (carbon emission caps, enacted 2019). While LL88's compliance deadlines extend well beyond the study period and LL97 does not bind until 2024, some anticipation effects cannot be ruled out. However, any anticipation of LL97's carbon compliance costs would bias the estimate \textit{toward} finding a negative effect (owners would rationally capitalize future costs into current values), making the null result conservative. A placebo test at the 50,000 sq ft threshold---where LL87 (energy audits) has applied since 2009 but LL84 expanded only in 2016---could further isolate the LL84 effect; this is left for future work.

\subsection{Policy Implications}

Despite these caveats, the results have direct implications for the ongoing expansion of building benchmarking mandates. Over thirty U.S.\ cities have adopted or are considering energy disclosure requirements for commercial buildings. The empirical basis for these policies rests largely on correlational evidence from voluntary green building certifications, supplemented by economic theory about information asymmetry.

This paper suggests that the informational case for mandatory benchmarking may be overstated---at least in its effect on property values. The commercial real estate market, at least for mid-size buildings in a major metropolitan area, appears to already incorporate energy performance information through private channels. Mandatory disclosure may be filling an information gap that does not exist at the building transaction margin.

This does not mean that benchmarking mandates are without value. Public benchmarking data serves important functions beyond the property market: it enables city-level energy planning, supports research on building energy performance, creates administrative infrastructure for carbon cap-and-trade programs (like LL97), and may shift public discourse about building energy use. The contribution of this paper is to show that the \textit{property market} channel---the mechanism most commonly invoked to justify disclosure mandates---does not appear to be operative.

Policymakers considering new benchmarking mandates should evaluate them on their administrative and informational merits rather than on the expectation that disclosure will transform property markets. Where the goal is market transformation, more direct interventions---energy performance standards, financial incentives for efficiency upgrades, or carbon pricing---may be more effective than information provision alone.

%% ============================================================
%% CONCLUSION
%% ============================================================
\section{Conclusion}

This paper uses a sharp regression discontinuity at the 25,000 square foot threshold of New York City's Local Law 84 to estimate the causal effect of mandatory energy benchmarking disclosure on property values. The setting offers a clean identification opportunity: a strong first stage (42.3 percentage point jump in compliance), no compound treatments at the threshold during the study period, and no evidence of manipulation in the running variable.

The answer is a well-powered null. The RDD estimate is $-0.040$ (robust SE $= 0.059$, $p = 0.591$), and this zero survives every robustness check I can devise: alternative bandwidths, polynomial orders, kernel functions, donut specifications, placebo cutoffs, and subgroup analyses by borough and construction era. The commercial real estate market in New York City does not price mandatory energy disclosure.

The most likely explanation is that the market already knows what benchmarking reveals. Energy costs are observable to motivated buyers, knowable to experienced brokers, and incorporated into operating statements shared during transactions. Public disclosure of this information through a government portal adds nothing to the effective information set of market participants.

Three decades of information economics taught us that sunlight is the best disinfectant. This paper offers an important caveat: you cannot disinfect a room that is already clean.

Future work should examine whether the null result holds over longer time horizons as disclosure norms mature, whether transaction-level price data reveals effects invisible in assessed values, and whether building segments with greater information asymmetry---such as small residential buildings---respond differently to disclosure mandates. The expansion of benchmarking to an ever-wider set of buildings and cities will provide ample quasi-experimental variation for these investigations.

\section*{Acknowledgements}

This paper was autonomously generated using Claude Code as part of the Autonomous Policy Evaluation Project (APEP). Data from the NYC Department of City Planning (PLUTO), NYC Mayor's Office of Sustainability (LL84 Benchmarking), NYC Department of Finance (Rolling Sales), and NYC Department of Buildings (Permits) were accessed via the NYC Open Data Socrata API.

\noindent\textbf{Project Repository:} \url{https://github.com/SocialCatalystLab/ape-papers}

\noindent\textbf{Contributors:} @ai1scl

\noindent\textbf{First Contributor:} \url{https://github.com/ai1scl}

\label{apep_main_text_end}
\newpage
\bibliography{references}

\newpage
\appendix

%% ============================================================
%% APPENDIX A: DATA
%% ============================================================
\section{Data Appendix}
\label{app:data}

\subsection{Data Sources and Access}

All data were obtained from the NYC Open Data portal (\url{https://opendata.cityofnewyork.us/}) via the Socrata Open Data API (SODA). Specific datasets:

\begin{enumerate}
    \item \textbf{PLUTO} (Primary Land Use Tax Lot Output): Dataset identifier \texttt{64uk-42ks}. Contains property characteristics for all tax lots in NYC. Accessed February 2026.

    \item \textbf{LL84 Benchmarking}: Dataset identifier \texttt{qb3v-bbre} (covered buildings list) and \texttt{usc3-8zwd} (benchmarking results). Contains energy and water performance data for buildings compliant with Local Law 84. Accessed February 2026.

    \item \textbf{DOF Rolling Sales}: Dataset identifier \texttt{usep-8jbt}. Contains records of all property sales in NYC. Accessed February 2026.

    \item \textbf{DOB Permits}: Dataset identifier \texttt{ipu4-2vta}. Contains records of all building permits filed in NYC. Accessed February 2026.
\end{enumerate}

\subsection{Sample Restrictions}

The following sample restrictions were applied sequentially:

\begin{enumerate}
    \item Begin with all tax lots in PLUTO with at least one building ($N \approx 1{,}085{,}000$).
    \item Restrict to building classes consistent with LL84 coverage: commercial (building classes C, K, O), mixed-use (classes M, R), and large residential (classes D, S with $\geq 10$ units). Drop purely industrial (F, G, I) and city-owned/tax-exempt properties.
    \item Require non-missing and positive gross floor area: $\text{GFA} > 0$.
    \item Require non-missing and positive assessed total value: $\text{assesstot} > 0$.
    \item For the \textit{broad} sample, restrict to $5{,}000 \leq \text{GFA} \leq 50{,}000$. This yields 82,238 buildings (70,124 below 25,000 sq ft; 12,114 above).
    \item For the \textit{narrow} sample, restrict to $15{,}000 \leq \text{GFA} \leq 35{,}000$. This yields 18,627 buildings (12,649 below; 5,978 above).
\end{enumerate}

\subsection{Variable Construction}

\textbf{Running variable:} Gross floor area (GFA) in square feet, from PLUTO field \texttt{bldgarea}. This measures the total area of all floors within the building envelope, including basements and attics if finished. It is computed from Department of Buildings records based on building plans and Certificates of Occupancy.

\textbf{Treatment:} $D_i = \ind[\text{GFA}_i \geq 25{,}000]$.

\textbf{Outcomes:}
\begin{itemize}
    \item Log assessed total value: $\ln(\texttt{assesstot})$. Assessed total value is the Department of Finance's estimate of market value for the purpose of property taxation. For income-producing properties, it is typically based on the income capitalization approach. For others, it uses comparable sales or the cost approach.
    \item Log assessed value per square foot: $\ln(\texttt{assesstot} / \texttt{bldgarea})$.
\end{itemize}

\textbf{LL84 compliance:} A building is classified as LL84-compliant if its BBL (borough-block-lot) identifier appears in the LL84 benchmarking dataset with at least one annual filing.

\textbf{Covariates:}
\begin{itemize}
    \item Year built: from PLUTO field \texttt{yearbuilt}. Missing or zero values dropped.
    \item Number of floors: from PLUTO field \texttt{numfloors}.
    \item Lot area: from PLUTO field \texttt{lotarea}, in square feet.
    \item Building age: $2024 - \texttt{yearbuilt}$.
    \item Borough: categorical, from PLUTO field \texttt{borough} (1 = Manhattan, 2 = Bronx, 3 = Brooklyn, 4 = Queens, 5 = Staten Island).
\end{itemize}

%% ============================================================
%% APPENDIX B: IDENTIFICATION
%% ============================================================
\section{Identification Appendix}
\label{app:identification}

\subsection{McCrary Density Test Details}

The McCrary density test is implemented using the \texttt{rddensity} package in R \citep{cattaneo2020rdrobust}. The test estimates the density of the running variable (GFA) separately on each side of the cutoff using local polynomial density estimation, and tests the null hypothesis of continuity. The test statistic is:
\[
T = \frac{\hat{f}_+(c) - \hat{f}_-(c)}{\sqrt{\hat{V}_+(c) + \hat{V}_-(c)}}
\]
where $\hat{f}_+(c)$ and $\hat{f}_-(c)$ are the right and left density estimates at the cutoff, and $\hat{V}_+(c)$ and $\hat{V}_-(c)$ are their estimated variances.

For our sample, $T = -0.010$ with $p = 0.992$. The estimated left density is virtually identical to the estimated right density, providing strong evidence against manipulation.

\subsection{Covariate Balance Details}

\Cref{tab:balance_details} reports the full covariate balance test results.

\begin{table}[H]
\centering
\caption{Covariate Balance at the 25,000 Sq Ft Threshold}
\label{tab:balance_details}
\small
\begin{tabular}{lccc}
\hline\hline
Covariate & RDD Estimate & Robust SE & $p$-value \\
\hline
Year built & 0.925 & 2.242 & 0.686 \\
Number of floors & 1.012 & 0.223 & 0.000 \\
Lot area (sq ft) & $-438.2$ & 350.5 & 0.248 \\
Building age & $-0.834$ & 2.271 & 0.715 \\
\hline\hline
\end{tabular}
\begin{minipage}{0.85\textwidth}
\vspace{0.3em}
\footnotesize \textit{Notes:} Each row reports the RDD estimate of the discontinuity in the indicated covariate at 25,000 sq ft using \texttt{rdrobust} with MSE-optimal bandwidth and triangular kernel. Bias-corrected robust standard errors.
\end{minipage}
\end{table}

The number of floors result warrants further discussion. A building's GFA equals approximately its footprint area multiplied by the number of floors. For buildings with a given footprint near the threshold, having one additional floor mechanically pushes GFA above 25,000 sq ft. This creates a discontinuity in floors at the threshold that is not evidence of sorting but rather a reflection of the deterministic relationship between the covariate and the running variable. The number of floors is a direct component of GFA, not an independent confounder. Similar covariate discontinuities arising from mechanical relationships with the running variable are discussed by \citet{lee2010rdd}.

\subsection{Interpretation of Donut RDD Results}

The donut RDD specifications provide a useful diagnostic but should be interpreted carefully. Excluding observations closest to the cutoff---which are the most informative for RDD estimation---increases variance substantially. The $\pm 2{,}000$ sq ft donut excludes buildings with GFA between 23,000 and 27,000 sq ft, leaving only observations 3,000--10,000 sq ft from the cutoff to identify the discontinuity. The resulting estimates are noisy ($p = 0.788$ in this case) but the sign reversal (positive estimate of $+0.070$) is not meaningful given the wide confidence intervals.

The $\pm 500$ and $\pm 1{,}000$ sq ft donut specifications, which exclude smaller neighborhoods of the cutoff, produce estimates more similar in magnitude to the baseline ($-0.098$ and $-0.171$, respectively) but with inflated standard errors. The uniformly insignificant results across donut radii indicate that the null finding is not driven by observations at any particular distance from the threshold.

%% ============================================================
%% APPENDIX C: ROBUSTNESS
%% ============================================================
\section{Robustness Appendix}
\label{app:robustness}

\subsection{Full Bandwidth Sensitivity}

The MSE-optimal bandwidth for the main specification is $h = 2{,}417$ sq ft, meaning the estimation uses buildings with GFA between 22,583 and 27,417 sq ft. This is a relatively narrow window, reflecting the fact that the conditional mean of log assessed value varies substantially with GFA, requiring a bandwidth that trades bias against variance.

To assess sensitivity, I estimate the RDD at bandwidths ranging from 1,209 sq ft (50\% of optimal) to 4,835 sq ft (200\% of optimal). At the narrowest bandwidth, the effective sample drops to approximately 1,200 buildings, and the estimate is very imprecise. At the widest bandwidth, the effective sample exceeds 8,000 buildings, providing substantial statistical power.

The pattern across bandwidths is informative: the point estimate becomes slightly more negative as the bandwidth increases (from $-0.015$ at 50\% to $-0.045$ at 200\%), but the standard errors shrink faster than the point estimates grow, so all estimates remain statistically insignificant. If there were a true discontinuity, we would expect wider bandwidths---which include more data and have less variance---to detect it. The fact that even the widest bandwidth fails to reject zero ($p = 0.305$) strengthens the null interpretation.

\subsection{Parametric Specifications}

In addition to the nonparametric \texttt{rdrobust} estimates, I estimate parametric specifications using OLS on the full narrow sample (15,000--35,000 sq ft):
\begin{equation}
Y_i = \alpha + \tau D_i + \sum_{p=1}^{P} \beta_p (X_i - c)^p + \sum_{p=1}^{P} \gamma_p D_i (X_i - c)^p + \delta' Z_i + \varepsilon_i
\end{equation}
where $Z_i$ includes borough fixed effects and $P$ ranges from 1 to 3. These parametric estimates use the full sample rather than a kernel-weighted local window.

The linear parametric estimate with borough fixed effects (Column 4 of \Cref{tab:main_results}) is $+0.005$ ($p = 0.805$). Quadratic and cubic parametric estimates are similarly small and insignificant (not tabulated). The parametric and nonparametric approaches agree: there is no discontinuity in property values at the LL84 threshold.

\subsection{Alternative Outcome Measures}

The primary analysis uses assessed values, which are available for all properties but may not perfectly reflect market conditions. As a supplementary check, I examined building permit filings as a proxy for investment activity. A positive investment response (Hypothesis 2) would predict more permit filings above the threshold. The RDD estimate on permit count is small and insignificant, consistent with the absence of a disclosure-induced investment response. However, building permits are a noisy proxy for energy-related investment, so this null should be interpreted with caution.

%% ============================================================
%% APPENDIX D: HETEROGENEITY
%% ============================================================
\section{Heterogeneity Appendix}
\label{app:heterogeneity}

\subsection{Borough-Level Analysis}

NYC's five boroughs represent dramatically different real estate markets. Manhattan's commercial market is characterized by institutional investors with sophisticated due diligence processes, where private information channels are most developed. Brooklyn's growing commercial market includes smaller, less institutional actors who may benefit more from public disclosure. Queens and the Bronx contain more industrial and warehouse properties at the 25,000 sq ft margin.

The borough-level estimates (\Cref{tab:heterogeneity}) reveal no systematic pattern that would suggest heterogeneous effects masked by the full-sample null. Manhattan, where information channels are richest, shows an exact zero ($p = 0.996$). Brooklyn shows the largest negative estimate ($p = 0.078$), which could indicate either a genuine (but small) effect in a market with less pre-existing information or a statistical artifact given the number of subgroups tested. The Bonferroni-corrected significance threshold for four tests is $p < 0.0125$, which Brooklyn does not meet.

The Bronx shows a positive point estimate ($+0.094$), opposite in sign to the other boroughs, which argues against any systematic negative effect of disclosure.

\subsection{Construction Era Analysis}

I divide buildings into three cohorts: pre-1940 (constructed during NYC's pre-war building boom), 1940--1980 (mid-century construction), and post-1980 (modern era). This split tests whether building vintage---which correlates with energy efficiency, construction methods, and building systems---moderates the disclosure effect.

Pre-1940 buildings, which constitute the majority of the sample (12,344 of 18,627 buildings in the narrow sample), show no effect ($p = 0.765$). These older buildings likely have the worst energy performance and the most to lose from disclosure---if disclosure were informative. The null for this large, presumably energy-inefficient cohort is strong evidence against the information revelation hypothesis.

The 1940--1980 cohort is the smallest (2,535 buildings) and shows the largest negative point estimate ($-0.100$), but with a $p$-value of 0.340 and wide confidence intervals due to the small sample. Post-1980 buildings show an estimate essentially at zero ($-0.002$, $p = 0.844$), which is expected if newer buildings are more homogeneous in energy performance, leaving less scope for information revelation.

\subsection{Multiple Testing Considerations}

Across seven subgroup estimates (four boroughs and three construction eras), one estimate (Brooklyn) has a $p$-value below 0.10, and none are below 0.05. Under the null hypothesis of no effects in any subgroup, we would expect approximately 0.7 out of 7 tests to be significant at the 10\% level by chance, and approximately 0.35 out of 7 at the 5\% level. The observed pattern---one marginal result out of seven tests---is entirely consistent with chance variation under the global null. A formal Bonferroni correction sets the per-test threshold at $0.05/7 \approx 0.007$; no subgroup estimate approaches this threshold.

%% ============================================================
%% APPENDIX E: ADDITIONAL EXHIBITS
%% ============================================================
\section{Additional Figures and Tables}
\label{app:exhibits}

\subsection{Main Results: Alternative Outcome}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig3_rdd_per_sqft.pdf}
\caption{RDD Plot: Log Assessed Value per Square Foot at the 25,000 Sq Ft Threshold}
\label{fig:rdd_per_sqft}
\begin{minipage}{0.9\textwidth}
\vspace{0.3em}
\footnotesize \textit{Notes:} Each point represents the mean log assessed value per square foot within a bin of building gross floor area. The solid lines are local polynomial fits estimated separately on each side of the 25,000 sq ft cutoff. The per-square-foot normalization removes the mechanical size-value relationship. No discontinuity is visible. This figure supports Column (3) of \Cref{tab:main_results} in the main text.
\end{minipage}
\end{figure}

\subsection{Validity Diagnostics: McCrary Density Test}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig1_density.pdf}
\caption{McCrary Density Test at the 25,000 Sq Ft Threshold}
\label{fig:density}
\begin{minipage}{0.9\textwidth}
\vspace{0.3em}
\footnotesize \textit{Notes:} Estimated density of building gross floor area using the \texttt{rddensity} package \citep{cattaneo2020rdrobust}. The vertical dashed line marks the 25,000 sq ft LL84 threshold. The estimated density discontinuity is $t = -0.010$ ($p = 0.992$), providing no evidence of sorting or manipulation.
\end{minipage}
\end{figure}

\subsection{Placebo Cutoffs: Numerical Estimates}

\input{tables/tab4_placebo.tex}

\subsection{Building Size Distribution}

The distribution of building GFA in the broad sample (5,000--50,000 sq ft) is right-skewed, with most buildings concentrated below 25,000 sq ft. The narrow sample (15,000--35,000 sq ft) provides a more balanced set of observations around the threshold, with 12,649 below and 5,978 above. The ratio of below-to-above observations (approximately 2:1) reflects the natural distribution of building sizes, not any threshold-related sorting.

\subsection{Temporal Context}

The analysis uses the most recent PLUTO release, which reflects assessed values incorporating information available through 2023. This cross-sectional design is appropriate because the RDD identifies a discontinuity in outcomes at the threshold at a point in time---it does not require panel variation. LL84's expansion to 25,000 sq ft took effect in 2016, providing approximately seven years for any property value effects to materialize in the cross-section. The assessed values used in the analysis reflect post-disclosure equilibrium conditions, giving the market ample time to capitalize any information value into property prices.

The primary identification concern is whether other policies create a discontinuity at exactly 25,000 sq ft. Local Law 97 (carbon emission caps, enacted 2019, enforced 2024) does share this threshold. However, LL97's compliance costs had not yet materialized during most of the sample period, and any anticipation effects would bias toward finding a \textit{negative} effect of threshold treatment (carbon cap costs capitalized into above-threshold values). The null result is therefore conservative with respect to LL97 contamination. Future research examining LL97's effects can use the 50,000 sq ft threshold (where LL97 compliance began) or exploit the 2019 enactment date in a difference-in-differences framework.

\subsection{Statistical Power}

A natural concern with null results is whether the study is sufficiently powered to detect economically meaningful effects. The effective sample of 3,740 buildings (at the MSE-optimal bandwidth) and the robust standard error of 0.059 imply a minimum detectable effect (at 80\% power, 5\% significance) of approximately $0.059 \times 2.8 \approx 0.165$ log points, or roughly 16\%. This means I can rule out effects larger than $\pm 16\%$ on property values. While this cannot rule out very small effects (e.g., 5\%), it is sufficient to detect the effect sizes documented in the green building premium literature. \citet{eichholtz2010doing} document ENERGY STAR certification premiums of 15--20\% on rents and sale prices. If mandatory disclosure produced effects of even half this magnitude, the present study would detect them with high probability.

At the widest bandwidth (200\% of optimal), the standard error falls to 0.051, and the minimum detectable effect is approximately 14\%. The conclusion is that the null result is informative: mandatory benchmarking disclosure does not generate property value effects comparable to those associated with voluntary green certifications.

\end{document}
